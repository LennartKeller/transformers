{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import random\n",
    "from turtle import forward\n",
    "from typing import Optional, Tuple, List, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import EvalPrediction\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable TopK-Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each layer only $k$ token-embeddings are selected and passed to the next layer.\n",
    "\n",
    "To make this operation differentiable it cannot use a hard selection scheme.\n",
    "\n",
    "The authors propose a an algorithm which uses two steps:\n",
    "\n",
    "1. Sorting\n",
    "   * The embeddings passed into the current layer are scored using a linear operation (e.g. dot product)\n",
    "   * The embeddings get sorted according to their score\n",
    "   * Question: Sorting is a non-differentiable or partially non-differentiable?\n",
    "   * Note: After selection the embeddings are re-arranged according to their original order????? This does not make any sense since they are positionally encoded???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 1000, (16, 512, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24, 119, 122,  ...,  58,  28,   2],\n",
       "         [  4,  77,  96,  ...,  84,  32,  97],\n",
       "         [  4, 122,  84,  ...,  62,  10,  49],\n",
       "         ...,\n",
       "         [100, 112,  77,  ...,   1, 116,  92],\n",
       "         [ 12, 104,  22,  ...,  83,  85,  29],\n",
       "         [ 99,  23,  45,  ..., 117,  43,   1]],\n",
       "\n",
       "        [[ 16,   8,  53,  ...,  69,  93,  65],\n",
       "         [  6, 127,  34,  ..., 117,  78,  99],\n",
       "         [ 38,  12,  61,  ...,  63,   9,  79],\n",
       "         ...,\n",
       "         [  7,  11, 117,  ...,  26,  74, 123],\n",
       "         [ 46, 126,  83,  ...,  15,   3,  97],\n",
       "         [ 42,  90,  24,  ...,  39,  58,  94]],\n",
       "\n",
       "        [[  0,  26,  37,  ...,  78, 106,   6],\n",
       "         [ 47,  27,  11,  ...,   0, 104,  73],\n",
       "         [ 25,  80,  16,  ...,  46,  41,  96],\n",
       "         ...,\n",
       "         [ 36,  12, 112,  ..., 117,  39,  29],\n",
       "         [ 72,  59,  48,  ...,  93,  68, 117],\n",
       "         [ 71,  90, 125,  ...,  40,  14,  41]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 13,  94,  79,  ...,  61, 108,  15],\n",
       "         [ 39, 123,  17,  ..., 122,  44, 112],\n",
       "         [ 34, 111,  75,  ...,  41,  60,  18],\n",
       "         ...,\n",
       "         [ 27,  99,  22,  ...,  74,  62,  36],\n",
       "         [103,  61,  75,  ...,  87,  29,   2],\n",
       "         [ 92, 122,  16,  ...,  89,  86, 123]],\n",
       "\n",
       "        [[114, 101,  36,  ...,   0,  43,  50],\n",
       "         [ 45,  82,  85,  ..., 125,  35,  46],\n",
       "         [125,  97,  92,  ...,   1,  53,  39],\n",
       "         ...,\n",
       "         [111,   2,  93,  ...,   7,   0, 112],\n",
       "         [ 98, 127,  94,  ..., 126,  69,  15],\n",
       "         [105,  35,  97,  ...,  43,  59,  21]],\n",
       "\n",
       "        [[ 42,   6, 121,  ...,   1,  21,  50],\n",
       "         [ 98,  72, 106,  ..., 119, 122,  61],\n",
       "         [ 32,  63,  10,  ...,  54,  98, 121],\n",
       "         ...,\n",
       "         [ 43,  29,  14,  ...,  81,   9,  30],\n",
       "         [ 91, 116,  79,  ...,  48,   4,  92],\n",
       "         [ 24,   8,  66,  ...,  43,  33,  94]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(x).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaked_softmax(x: Tensor, alpha: float = 0.1, dim: int = 0):\n",
    "    x = x * alpha\n",
    "    softmax = nn.Softmax(dim=dim)\n",
    "    return softmax(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn(10)\n",
    "for i in torch.linspace(1, 3, 10):\n",
    "    plt.plot(peaked_softmax(x, alpha=i.item()).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKPooler(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.scorer = nn.Sequential(\n",
    "            nn.Linear(in_features=embedding_dim, out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, embeddings: Tensor):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            embeddings (Tensor): tensor of shape (batch_size, n_embeddings,\n",
    "        \"\"\"\n",
    "        # 1. Score embeddings\n",
    "        scores = self.scorer(embeddings)\n",
    "        \n",
    "        # 2. Sort embeddings according to their score in descending order\n",
    "        embeddings_sorted, scores_sorted = self.sort_embeddings(embeddings=embeddings, scores=scores)\n",
    "\n",
    "        # 3. Create new tensors with pairs of embeddings and scores\n",
    "        # Create embeddings pairs\n",
    "\n",
    "        middle_idx = int(embeddings.size(1) // 2)\n",
    "        #print(middle_idx)\n",
    "\n",
    "        left_embeddings, right_embeddings = embeddings_sorted[:, :middle_idx, :], embeddings_sorted[:, middle_idx:, :]\n",
    "        embedding_pairs = torch.cat((left_embeddings.unsqueeze(3), right_embeddings.flip(1).unsqueeze(3)), dim=3)\n",
    "        #print(embedding_pairs.size())  # shape: bs, seqlen // 2, n_dim, 2\n",
    "\n",
    "        # Create score pairs\n",
    "\n",
    "        left_scores, right_scores = scores_sorted[:, :middle_idx, :], scores_sorted[:, middle_idx:, :]\n",
    "        score_pairs = torch.cat((left_scores.unsqueeze(3), right_scores.flip(1).unsqueeze(3)), dim=3)\n",
    "        #print(score_pairs.size())  # shape: bs, seqlen // 2, 1, 2\n",
    "\n",
    "        score_pairs_softmaxed = peaked_softmax(score_pairs, alpha=5.0, dim=3)\n",
    "        #print(score_pairs_softmaxed.size())\n",
    "\n",
    "        new_embeddings = (embedding_pairs * score_pairs_softmaxed).sum(dim=3)\n",
    "        #print(new_embeddings.size())\n",
    "        return new_embeddings    \n",
    "    \n",
    "    def sort_embeddings(self, embeddings: Tensor, scores: Tensor):\n",
    "        \"\"\"Sorts the embeddings and score according to their score in descending order\n",
    "\n",
    "        Args:\n",
    "            embeddings (Tensor): tensor of shape (batch_size, n_embeddings, n_dims)\n",
    "            scores (Tensor): (batch_size, n_embeddings, 1)\n",
    "\n",
    "        Returns:\n",
    "            _type_: Sorted embeddings and scores\n",
    "        \"\"\"\n",
    "        sort_idc = scores.sort(descending=True, dim=1).indices\n",
    "        #print(sort_idc.size())\n",
    "        \n",
    "        embeddings_sorted = self.sort_by_indices(embeddings, sort_idc)  #???\n",
    "        #print(embeddings_sorted.size())\n",
    "        \n",
    "        scores_sorted = self.sort_by_indices(scores, sort_idc)  #???\n",
    "        #print(scores_sorted.size())\n",
    "        \n",
    "        return embeddings_sorted, scores_sorted\n",
    "    \n",
    "    @staticmethod\n",
    "    def sort_by_indices(embeddings, indices):\n",
    "        sorted_batches = []\n",
    "        for batch_embeddings, batch_scores in zip(embeddings, indices):\n",
    "            sorted_batches.append(batch_embeddings[batch_scores.reshape(-1)].unsqueeze(0))\n",
    "        return torch.cat(sorted_batches, dim=0)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (1): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (2): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (3): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (4): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (5): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (6): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (7): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (8): TopKPooler(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = torch.log2(torch.tensor(512)).long().item()\n",
    "\n",
    "pyramid = nn.Sequential(*(\n",
    "    TopKPooler(embedding_dim=768)\n",
    "    for _ in range(n_layers)\n",
    "))\n",
    "pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 768])\n",
      "torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "src = torch.randn(8, 512, 768)\n",
    "trgt = src[:, 64, :]\n",
    "print(src.size())\n",
    "print(trgt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pyramid(src)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9856: 100%|██████████| 10/10 [00:00<00:00, 19.51it/s]\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD(params=pyramid.parameters(), lr=0.1)\n",
    "pbar = tqdm(list(range(10)))\n",
    "for _ in pbar:\n",
    "    out = pyramid(src).squeeze(1)\n",
    "    loss_fct = nn.MSELoss()\n",
    "    loss = loss_fct(out, trgt)\n",
    "    pbar.set_description(f\"Loss: {round(loss.item(), 4)}\")\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0332, -0.0208,  0.0702,  ..., -0.0905, -0.0324, -0.0400],\n",
      "        [-0.0128, -0.0196,  0.0409,  ..., -0.0531, -0.0166,  0.0094],\n",
      "        [ 0.1158, -0.1732, -0.1092,  ...,  0.0111, -0.0612,  0.0165],\n",
      "        ...,\n",
      "        [ 0.0234, -0.0765,  0.1523,  ..., -0.0476, -0.0183,  0.0464],\n",
      "        [-0.0643,  0.0276,  0.0675,  ..., -0.0098, -0.0119, -0.0564],\n",
      "        [ 0.1530, -0.0729, -0.0031,  ...,  0.0888, -0.0047, -0.1614]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[-0.1942,  0.6379, -0.3457,  ..., -1.0045, -0.4812,  0.9927],\n",
      "        [ 0.7160,  1.1301,  0.3286,  ...,  0.2789,  0.9490, -0.4316],\n",
      "        [-0.5369,  1.6008, -1.8433,  ..., -0.8403, -0.2150,  0.2143],\n",
      "        ...,\n",
      "        [-0.0837, -0.5883,  0.9293,  ...,  0.0957, -0.9959, -0.0143],\n",
      "        [ 0.9582, -0.5126,  2.0424,  ...,  0.5452,  0.4282, -0.7062],\n",
      "        [ 1.0666, -0.6540, -0.9030,  ...,  1.7305,  0.5118, -0.8643]])\n"
     ]
    }
   ],
   "source": [
    "out = pyramid(src).squeeze(1)\n",
    "print(out)\n",
    "print(trgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1942,  0.6379, -0.3457,  ..., -1.0045, -0.4812,  0.9927],\n",
       "        [ 0.7160,  1.1301,  0.3286,  ...,  0.2789,  0.9490, -0.4316],\n",
       "        [-0.5369,  1.6008, -1.8433,  ..., -0.8403, -0.2150,  0.2143],\n",
       "        ...,\n",
       "        [-0.0837, -0.5883,  0.9293,  ...,  0.0957, -0.9959, -0.0143],\n",
       "        [ 0.9582, -0.5126,  2.0424,  ...,  0.5452,  0.4282, -0.7062],\n",
       "        [ 1.0666, -0.6540, -0.9030,  ...,  1.7305,  0.5118, -0.8643]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(16, 512, 1).squeeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "e = torch.tensor([\n",
    "    [\n",
    "        [0.1, 1.9],\n",
    "        [0.0, 0.5],\n",
    "        [0.7, 0.9]\n",
    "    ],\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 0.5],\n",
    "        [0.7, 0.9]\n",
    "    ]\n",
    "])\n",
    "print(e.size())\n",
    "\n",
    "s = torch.tensor([\n",
    "    [\n",
    "        [0],\n",
    "        [2],\n",
    "        [1]\n",
    "    ],\n",
    "    [\n",
    "        [2],\n",
    "        [1],\n",
    "        [0]\n",
    "    ],\n",
    "])\n",
    "print(s.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 8, 7, 6, 5, 4, 3, 2, 1, 0],\n",
       "        [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10).repeat(2).reshape(2, -1).flip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "* Pyramdion only serves as encoder model?\n",
    "* Which architecture to use for decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PyramidionsConfig, PyramidionsModel, RobertaTokenizer, PyramidionsForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids = torch.arange(\n",
    "            1 + 1, 512 + 1 + 1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
       "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
       "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
       "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
       "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "        408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
       "        422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
       "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
       "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
       "        464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
       "        478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "        492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
       "        506, 507, 508, 509, 510, 511, 512, 513])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyramidionsConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"pyramidions\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 9,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PyramidionsConfig()\n",
    "config.update({\"num_hidden_layers\": 9, \"max_position_embeddings\": 514, \"type_vocab_size\": 2, \"type_vocab_size\": 1})\n",
    "print(config)\n",
    "model = PyramidionsForSequenceClassification(config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[0.2860, 0.6765]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokenizer(\"Hallo\", padding=\"max_length\", return_tensors=\"pt\"))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "pretrained_model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def rename_roberta_state_dict(state_dict):\n",
    "    return OrderedDict([(f\"pyramidions.{key}\", value) for key, value in state_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['pyramidions.encoder.layer.0.pooler.scorer.0.weight', 'pyramidions.encoder.layer.0.pooler.scorer.0.bias', 'pyramidions.encoder.layer.1.pooler.scorer.0.weight', 'pyramidions.encoder.layer.1.pooler.scorer.0.bias', 'pyramidions.encoder.layer.2.pooler.scorer.0.weight', 'pyramidions.encoder.layer.2.pooler.scorer.0.bias', 'pyramidions.encoder.layer.3.pooler.scorer.0.weight', 'pyramidions.encoder.layer.3.pooler.scorer.0.bias', 'pyramidions.encoder.layer.4.pooler.scorer.0.weight', 'pyramidions.encoder.layer.4.pooler.scorer.0.bias', 'pyramidions.encoder.layer.5.pooler.scorer.0.weight', 'pyramidions.encoder.layer.5.pooler.scorer.0.bias', 'pyramidions.encoder.layer.6.pooler.scorer.0.weight', 'pyramidions.encoder.layer.6.pooler.scorer.0.bias', 'pyramidions.encoder.layer.7.pooler.scorer.0.weight', 'pyramidions.encoder.layer.7.pooler.scorer.0.bias', 'pyramidions.encoder.layer.8.pooler.scorer.0.weight', 'pyramidions.encoder.layer.8.pooler.scorer.0.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'], unexpected_keys=['pyramidions.pooler.dense.weight', 'pyramidions.pooler.dense.bias', 'pyramidions.encoder.layer.9.attention.self.query.weight', 'pyramidions.encoder.layer.9.attention.self.query.bias', 'pyramidions.encoder.layer.9.attention.self.key.weight', 'pyramidions.encoder.layer.9.attention.self.key.bias', 'pyramidions.encoder.layer.9.attention.self.value.weight', 'pyramidions.encoder.layer.9.attention.self.value.bias', 'pyramidions.encoder.layer.9.attention.output.dense.weight', 'pyramidions.encoder.layer.9.attention.output.dense.bias', 'pyramidions.encoder.layer.9.attention.output.LayerNorm.weight', 'pyramidions.encoder.layer.9.attention.output.LayerNorm.bias', 'pyramidions.encoder.layer.9.intermediate.dense.weight', 'pyramidions.encoder.layer.9.intermediate.dense.bias', 'pyramidions.encoder.layer.9.output.dense.weight', 'pyramidions.encoder.layer.9.output.dense.bias', 'pyramidions.encoder.layer.9.output.LayerNorm.weight', 'pyramidions.encoder.layer.9.output.LayerNorm.bias', 'pyramidions.encoder.layer.10.attention.self.query.weight', 'pyramidions.encoder.layer.10.attention.self.query.bias', 'pyramidions.encoder.layer.10.attention.self.key.weight', 'pyramidions.encoder.layer.10.attention.self.key.bias', 'pyramidions.encoder.layer.10.attention.self.value.weight', 'pyramidions.encoder.layer.10.attention.self.value.bias', 'pyramidions.encoder.layer.10.attention.output.dense.weight', 'pyramidions.encoder.layer.10.attention.output.dense.bias', 'pyramidions.encoder.layer.10.attention.output.LayerNorm.weight', 'pyramidions.encoder.layer.10.attention.output.LayerNorm.bias', 'pyramidions.encoder.layer.10.intermediate.dense.weight', 'pyramidions.encoder.layer.10.intermediate.dense.bias', 'pyramidions.encoder.layer.10.output.dense.weight', 'pyramidions.encoder.layer.10.output.dense.bias', 'pyramidions.encoder.layer.10.output.LayerNorm.weight', 'pyramidions.encoder.layer.10.output.LayerNorm.bias', 'pyramidions.encoder.layer.11.attention.self.query.weight', 'pyramidions.encoder.layer.11.attention.self.query.bias', 'pyramidions.encoder.layer.11.attention.self.key.weight', 'pyramidions.encoder.layer.11.attention.self.key.bias', 'pyramidions.encoder.layer.11.attention.self.value.weight', 'pyramidions.encoder.layer.11.attention.self.value.bias', 'pyramidions.encoder.layer.11.attention.output.dense.weight', 'pyramidions.encoder.layer.11.attention.output.dense.bias', 'pyramidions.encoder.layer.11.attention.output.LayerNorm.weight', 'pyramidions.encoder.layer.11.attention.output.LayerNorm.bias', 'pyramidions.encoder.layer.11.intermediate.dense.weight', 'pyramidions.encoder.layer.11.intermediate.dense.bias', 'pyramidions.encoder.layer.11.output.dense.weight', 'pyramidions.encoder.layer.11.output.dense.bias', 'pyramidions.encoder.layer.11.output.LayerNorm.weight', 'pyramidions.encoder.layer.11.output.LayerNorm.bias'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(rename_roberta_state_dict(pretrained_model.state_dict()), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 908.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-54aedbefd2676f9d.arrow\n",
      "Loading cached processed dataset at /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-837877adeb715f8d.arrow\n",
      "Loading cached processed dataset at /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-7a2499041269e44e.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda row: tokenizer(row[\"text\"], truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-fbe91050e3d66a64.arrow and /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-356559fca645c6ee.arrow\n",
      "Loading cached split indices for dataset at /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-71955fa8d9f973c9.arrow and /Users/lennartkeller/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5d0a255d00574d45.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2375\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_format(\"torch\")\n",
    "dataset.rename_column(\"label\", \"labels\")\n",
    "dataset.remove_columns(\"text\")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.15, seed=42)[\"test\"]\n",
    "dataset = dataset.train_test_split(test_size=0.05, seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "# I think that the trainer is not using the right padding strategy....\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\"pyramid_classif\",\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorWithPadding(padding=\"max_length\", tokenizer=tokenizer),\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/lennartkeller/Uni/transformers/src/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2375\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 297\n",
      "  0%|          | 1/297 [00:01<07:48,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6859, 'learning_rate': 2.98989898989899e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/297 [00:03<07:53,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6405, 'learning_rate': 2.97979797979798e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/297 [00:04<07:23,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6224, 'learning_rate': 2.96969696969697e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/297 [00:06<07:13,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9514, 'learning_rate': 2.9595959595959595e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/297 [00:07<07:02,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6967, 'learning_rate': 2.9494949494949495e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/297 [00:08<06:52,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6876, 'learning_rate': 2.9393939393939394e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/297 [00:10<06:45,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6212, 'learning_rate': 2.9292929292929294e-05, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/297 [00:11<06:45,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6258, 'learning_rate': 2.9191919191919193e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/297 [00:12<06:40,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6763, 'learning_rate': 2.9090909090909093e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/297 [00:14<06:46,  1.41s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8403, 'learning_rate': 2.8989898989898992e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      "  3%|▎         | 10/297 [00:19<06:46,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7184760570526123, 'eval_accuracy': 0.46399998664855957, 'eval_runtime': 5.347, 'eval_samples_per_second': 23.378, 'eval_steps_per_second': 2.992, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/297 [00:21<14:28,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6218, 'learning_rate': 2.8888888888888888e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/297 [00:22<12:02,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7624, 'learning_rate': 2.8787878787878788e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/297 [00:23<10:17,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6979, 'learning_rate': 2.8686868686868687e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/297 [00:25<09:05,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7276, 'learning_rate': 2.8585858585858587e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/297 [00:26<08:18,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6744, 'learning_rate': 2.8484848484848486e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/297 [00:27<07:44,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6553, 'learning_rate': 2.8383838383838386e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/297 [00:29<07:17,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7322, 'learning_rate': 2.8282828282828285e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/297 [00:30<07:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6945, 'learning_rate': 2.8181818181818185e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/297 [00:32<06:46,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6614, 'learning_rate': 2.808080808080808e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/297 [00:33<06:38,  1.44s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6606, 'learning_rate': 2.797979797979798e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      "  7%|▋         | 20/297 [00:38<06:38,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6929615139961243, 'eval_accuracy': 0.5360000133514404, 'eval_runtime': 5.4531, 'eval_samples_per_second': 22.923, 'eval_steps_per_second': 2.934, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/297 [00:40<14:05,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6276, 'learning_rate': 2.787878787878788e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/297 [00:41<11:44,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6565, 'learning_rate': 2.777777777777778e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/297 [00:43<10:03,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7582, 'learning_rate': 2.767676767676768e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/297 [00:44<08:53,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7678, 'learning_rate': 2.7575757575757578e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/297 [00:45<08:03,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6583, 'learning_rate': 2.7474747474747478e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 26/297 [00:47<07:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6248, 'learning_rate': 2.7373737373737374e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/297 [00:48<07:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6675, 'learning_rate': 2.7272727272727273e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/297 [00:49<06:46,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5933, 'learning_rate': 2.7171717171717173e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/297 [00:51<06:33,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7487, 'learning_rate': 2.7070707070707072e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/297 [00:52<06:25,  1.44s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6791, 'learning_rate': 2.696969696969697e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|█         | 30/297 [00:58<06:25,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.702253520488739, 'eval_accuracy': 0.4320000112056732, 'eval_runtime': 5.4563, 'eval_samples_per_second': 22.909, 'eval_steps_per_second': 2.932, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/297 [00:59<13:36,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7627, 'learning_rate': 2.686868686868687e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/297 [01:00<11:17,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8576, 'learning_rate': 2.676767676767677e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/297 [01:02<09:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6827, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 34/297 [01:03<08:35,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6667, 'learning_rate': 2.6565656565656566e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/297 [01:05<07:47,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7684, 'learning_rate': 2.6464646464646466e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/297 [01:06<07:14,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7035, 'learning_rate': 2.6363636363636365e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/297 [01:07<06:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7147, 'learning_rate': 2.6262626262626265e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/297 [01:09<06:32,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7231, 'learning_rate': 2.6161616161616164e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 39/297 [01:10<06:20,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6808, 'learning_rate': 2.6060606060606063e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/297 [01:11<06:12,  1.45s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6796, 'learning_rate': 2.595959595959596e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 13%|█▎        | 40/297 [01:17<06:12,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6864455938339233, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 5.4298, 'eval_samples_per_second': 23.021, 'eval_steps_per_second': 2.947, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 41/297 [01:18<13:02,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6368, 'learning_rate': 2.585858585858586e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/297 [01:20<10:51,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7312, 'learning_rate': 2.575757575757576e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/297 [01:21<09:21,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6568, 'learning_rate': 2.5656565656565658e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/297 [01:22<08:18,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6797, 'learning_rate': 2.5555555555555557e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/297 [01:24<07:35,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6521, 'learning_rate': 2.5454545454545457e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 46/297 [01:25<07:04,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7405, 'learning_rate': 2.5353535353535356e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/297 [01:27<06:44,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7114, 'learning_rate': 2.5252525252525256e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/297 [01:28<06:32,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6619, 'learning_rate': 2.5151515151515152e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/297 [01:30<06:25,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6433, 'learning_rate': 2.505050505050505e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/297 [01:31<06:29,  1.58s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7274, 'learning_rate': 2.494949494949495e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 17%|█▋        | 50/297 [01:37<06:29,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.685123085975647, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 5.6542, 'eval_samples_per_second': 22.108, 'eval_steps_per_second': 2.83, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/297 [01:38<13:18,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7418, 'learning_rate': 2.484848484848485e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 52/297 [01:40<11:01,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7956, 'learning_rate': 2.474747474747475e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/297 [01:41<09:26,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7356, 'learning_rate': 2.464646464646465e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 54/297 [01:43<08:17,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6649, 'learning_rate': 2.454545454545455e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 55/297 [01:44<07:31,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7498, 'learning_rate': 2.4444444444444445e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 56/297 [01:46<06:56,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6259, 'learning_rate': 2.4343434343434344e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/297 [01:47<06:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6779, 'learning_rate': 2.4242424242424244e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 58/297 [01:48<06:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.681, 'learning_rate': 2.4141414141414143e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/297 [01:50<06:03,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6735, 'learning_rate': 2.4040404040404043e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/297 [01:51<05:55,  1.50s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5997, 'learning_rate': 2.3939393939393942e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|██        | 60/297 [01:57<05:55,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6868980526924133, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 5.6462, 'eval_samples_per_second': 22.139, 'eval_steps_per_second': 2.834, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 61/297 [01:58<12:30,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6789, 'learning_rate': 2.3838383838383842e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/297 [02:00<10:25,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6886, 'learning_rate': 2.3737373737373738e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 63/297 [02:01<09:05,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6942, 'learning_rate': 2.3636363636363637e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 64/297 [02:03<08:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7164, 'learning_rate': 2.3535353535353537e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 65/297 [02:04<07:18,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6589, 'learning_rate': 2.3434343434343436e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/297 [02:06<06:45,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.673, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 67/297 [02:07<06:21,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.736, 'learning_rate': 2.3232323232323235e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/297 [02:09<06:05,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6883, 'learning_rate': 2.3131313131313135e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 69/297 [02:10<05:53,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7527, 'learning_rate': 2.303030303030303e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 70/297 [02:12<05:43,  1.51s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7039, 'learning_rate': 2.292929292929293e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 24%|██▎       | 70/297 [02:17<05:43,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6951676607131958, 'eval_accuracy': 0.4880000054836273, 'eval_runtime': 5.6693, 'eval_samples_per_second': 22.049, 'eval_steps_per_second': 2.822, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 71/297 [02:19<11:59,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7212, 'learning_rate': 2.282828282828283e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 72/297 [02:20<09:55,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7021, 'learning_rate': 2.272727272727273e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 73/297 [02:21<08:32,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6903, 'learning_rate': 2.262626262626263e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 74/297 [02:23<07:37,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7056, 'learning_rate': 2.2525252525252525e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 75/297 [02:24<06:58,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7098, 'learning_rate': 2.2424242424242424e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 76/297 [02:26<06:34,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7185, 'learning_rate': 2.2323232323232324e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/297 [02:27<06:08,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.742, 'learning_rate': 2.222222222222222e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 78/297 [02:29<05:49,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6791, 'learning_rate': 2.212121212121212e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 79/297 [02:30<05:36,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6842, 'learning_rate': 2.202020202020202e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/297 [02:32<05:28,  1.51s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6866, 'learning_rate': 2.191919191919192e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 27%|██▋       | 80/297 [02:37<05:28,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6835117340087891, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 5.6434, 'eval_samples_per_second': 22.15, 'eval_steps_per_second': 2.835, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/297 [02:39<11:27,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6625, 'learning_rate': 2.1818181818181818e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 82/297 [02:40<09:31,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6923, 'learning_rate': 2.1717171717171717e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/297 [02:42<08:08,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7227, 'learning_rate': 2.1616161616161617e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/297 [02:43<07:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5826, 'learning_rate': 2.1515151515151513e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 85/297 [02:45<06:31,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6969, 'learning_rate': 2.1414141414141412e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 86/297 [02:46<06:07,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7744, 'learning_rate': 2.1313131313131312e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/297 [02:47<05:45,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6842, 'learning_rate': 2.121212121212121e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 88/297 [02:49<05:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7727, 'learning_rate': 2.111111111111111e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/297 [02:51<05:55,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6123, 'learning_rate': 2.101010101010101e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 90/297 [02:52<05:45,  1.67s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6218, 'learning_rate': 2.090909090909091e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 30%|███       | 90/297 [02:58<05:45,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6835306286811829, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 5.7239, 'eval_samples_per_second': 21.838, 'eval_steps_per_second': 2.795, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 91/297 [03:00<11:24,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.789, 'learning_rate': 2.0808080808080806e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/297 [03:01<09:28,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7971, 'learning_rate': 2.0707070707070705e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 93/297 [03:03<08:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7114, 'learning_rate': 2.0606060606060605e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 94/297 [03:04<07:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6883, 'learning_rate': 2.0505050505050504e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/297 [03:05<06:20,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7136, 'learning_rate': 2.0404040404040404e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/297 [03:07<05:52,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.651, 'learning_rate': 2.0303030303030303e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 97/297 [03:08<05:32,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6501, 'learning_rate': 2.0202020202020203e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 98/297 [03:10<05:18,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6918, 'learning_rate': 2.01010101010101e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/297 [03:11<05:12,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6554, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 100/297 [03:13<05:04,  1.55s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6608, 'learning_rate': 1.9898989898989898e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 34%|███▎      | 100/297 [03:19<05:04,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6870543956756592, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 6.0037, 'eval_samples_per_second': 20.821, 'eval_steps_per_second': 2.665, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 101/297 [03:20<10:49,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6945, 'learning_rate': 1.9797979797979797e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/297 [03:22<08:58,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7037, 'learning_rate': 1.9696969696969697e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 103/297 [03:23<07:38,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7012, 'learning_rate': 1.9595959595959596e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 104/297 [03:25<06:42,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6876, 'learning_rate': 1.9494949494949496e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 105/297 [03:26<06:03,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.64, 'learning_rate': 1.9393939393939395e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 106/297 [03:27<05:36,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6326, 'learning_rate': 1.929292929292929e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/297 [03:29<05:17,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6591, 'learning_rate': 1.919191919191919e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 108/297 [03:30<05:03,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6365, 'learning_rate': 1.909090909090909e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 109/297 [03:32<04:56,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6418, 'learning_rate': 1.898989898989899e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/297 [03:33<04:50,  1.55s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7012, 'learning_rate': 1.888888888888889e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 37%|███▋      | 110/297 [03:39<04:50,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6838167905807495, 'eval_accuracy': 0.5680000185966492, 'eval_runtime': 6.0614, 'eval_samples_per_second': 20.622, 'eval_steps_per_second': 2.64, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 111/297 [03:41<10:37,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7083, 'learning_rate': 1.878787878787879e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 112/297 [03:43<08:46,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7423, 'learning_rate': 1.8686868686868688e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/297 [03:44<07:27,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7499, 'learning_rate': 1.8585858585858584e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 114/297 [03:46<06:35,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.814, 'learning_rate': 1.8484848484848484e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 115/297 [03:47<05:55,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7803, 'learning_rate': 1.8383838383838383e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 116/297 [03:49<05:28,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6993, 'learning_rate': 1.8282828282828283e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/297 [03:50<05:07,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7776, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 118/297 [03:52<04:52,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7049, 'learning_rate': 1.808080808080808e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 119/297 [03:53<04:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.677, 'learning_rate': 1.797979797979798e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/297 [03:54<04:32,  1.54s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.709, 'learning_rate': 1.7878787878787877e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|████      | 120/297 [04:00<04:32,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6915966868400574, 'eval_accuracy': 0.5440000295639038, 'eval_runtime': 5.7723, 'eval_samples_per_second': 21.655, 'eval_steps_per_second': 2.772, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 121/297 [04:02<09:31,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6821, 'learning_rate': 1.7777777777777777e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/297 [04:03<07:53,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.69, 'learning_rate': 1.7676767676767676e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 123/297 [04:05<06:44,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6602, 'learning_rate': 1.7575757575757576e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 124/297 [04:06<05:56,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.718, 'learning_rate': 1.7474747474747475e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/297 [04:07<05:23,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6927, 'learning_rate': 1.7373737373737375e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/297 [04:09<04:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7386, 'learning_rate': 1.7272727272727274e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 127/297 [04:10<04:40,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7616, 'learning_rate': 1.717171717171717e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/297 [04:12<04:29,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7337, 'learning_rate': 1.707070707070707e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/297 [04:13<04:22,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6848, 'learning_rate': 1.696969696969697e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 130/297 [04:15<04:16,  1.54s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7673, 'learning_rate': 1.686868686868687e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 44%|████▍     | 130/297 [04:21<04:16,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6999815106391907, 'eval_accuracy': 0.4320000112056732, 'eval_runtime': 5.8746, 'eval_samples_per_second': 21.278, 'eval_steps_per_second': 2.724, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 131/297 [04:22<09:03,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7313, 'learning_rate': 1.6767676767676768e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/297 [04:23<07:30,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7165, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 133/297 [04:25<06:27,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7002, 'learning_rate': 1.6565656565656567e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 134/297 [04:26<05:40,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7167, 'learning_rate': 1.6464646464646466e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/297 [04:28<05:08,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6753, 'learning_rate': 1.6363636363636363e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 136/297 [04:29<04:44,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7152, 'learning_rate': 1.6262626262626262e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/297 [04:31<04:27,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.677, 'learning_rate': 1.616161616161616e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 138/297 [04:32<04:15,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7221, 'learning_rate': 1.606060606060606e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 139/297 [04:34<04:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6876, 'learning_rate': 1.595959595959596e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 140/297 [04:35<04:00,  1.53s/it]The following columns in the evaluation set  don't have a corresponding argument in `PyramidionsForSequenceClassification.forward` and have been ignored: text. If text are not expected by `PyramidionsForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 125\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6742, 'learning_rate': 1.585858585858586e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 47%|████▋     | 140/297 [04:41<04:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6937568187713623, 'eval_accuracy': 0.4959999918937683, 'eval_runtime': 6.0039, 'eval_samples_per_second': 20.82, 'eval_steps_per_second': 2.665, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/297 [04:43<08:37,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6758, 'learning_rate': 1.575757575757576e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 142/297 [04:44<07:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7232, 'learning_rate': 1.5656565656565655e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/297 [04:46<06:03,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7322, 'learning_rate': 1.5555555555555555e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/297 [04:47<05:19,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6727, 'learning_rate': 1.5454545454545454e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 145/297 [04:48<04:48,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6858, 'learning_rate': 1.5353535353535354e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 146/297 [04:50<04:25,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6922, 'learning_rate': 1.5252525252525253e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/297 [04:51<04:11,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7219, 'learning_rate': 1.5151515151515153e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 148/297 [04:53<04:02,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7106, 'learning_rate': 1.5050505050505052e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 149/297 [04:54<03:55,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6756, 'learning_rate': 1.494949494949495e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/test_bench.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/test_bench.ipynb#ch0000029?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/trainer.py:1429\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1426'>1427</a>\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1427'>1428</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1428'>1429</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1430'>1431</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1431'>1432</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1432'>1433</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1433'>1434</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1434'>1435</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1435'>1436</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=1436'>1437</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/trainer.py:2058\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2054'>2055</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2056'>2057</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocast_smart_context_manager():\n\u001b[0;32m-> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2057'>2058</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2059'>2060</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2060'>2061</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/trainer.py:2090\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2087'>2088</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2088'>2089</a>\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2089'>2090</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2090'>2091</a>\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2091'>2092</a>\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/trainer.py?line=2092'>2093</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:1286\u001b[0m, in \u001b[0;36mPyramidionsForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1277'>1278</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1278'>1279</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1279'>1280</a>\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1280'>1281</a>\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1281'>1282</a>\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1282'>1283</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1283'>1284</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1285'>1286</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyramidions(\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1286'>1287</a>\u001b[0m     input_ids,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1287'>1288</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1288'>1289</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1289'>1290</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1290'>1291</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1291'>1292</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1292'>1293</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1293'>1294</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1294'>1295</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1295'>1296</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1296'>1297</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=1297'>1298</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:924\u001b[0m, in \u001b[0;36mPyramidionsModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=914'>915</a>\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=916'>917</a>\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=917'>918</a>\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=918'>919</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=921'>922</a>\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=922'>923</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=923'>924</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=924'>925</a>\u001b[0m     embedding_output,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=925'>926</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=926'>927</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=927'>928</a>\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=928'>929</a>\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=929'>930</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=930'>931</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=931'>932</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=932'>933</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=933'>934</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=934'>935</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=935'>936</a>\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=936'>937</a>\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:601\u001b[0m, in \u001b[0;36mPyramidionsEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=591'>592</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=592'>593</a>\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=593'>594</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=597'>598</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=598'>599</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=599'>600</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=600'>601</a>\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=601'>602</a>\u001b[0m         hidden_states,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=602'>603</a>\u001b[0m         attention_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=603'>604</a>\u001b[0m         layer_head_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=604'>605</a>\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=605'>606</a>\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=606'>607</a>\u001b[0m         past_key_value,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=607'>608</a>\u001b[0m         output_attentions,\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=608'>609</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=610'>611</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=611'>612</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:526\u001b[0m, in \u001b[0;36mPyramidionsLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=522'>523</a>\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=523'>524</a>\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=525'>526</a>\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=526'>527</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=527'>528</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=528'>529</a>\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=530'>531</a>\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/pytorch_utils.py?line=237'>238</a>\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/pytorch_utils.py?line=238'>239</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/pytorch_utils.py?line=240'>241</a>\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:540\u001b[0m, in \u001b[0;36mPyramidionsLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=538'>539</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=539'>540</a>\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=540'>541</a>\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py:432\u001b[0m, in \u001b[0;36mPyramidionsIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=430'>431</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=431'>432</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=432'>433</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    <a href='file:///Users/lennartkeller/Uni/transformers/src/transformers/models/pyramidions/modeling_pyramidions.py?line=433'>434</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/transformers_dev/lib/python3.9/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c90e30c2b7961fb97c896d6f081d6fe926e201bd9b65942b4a0d17f0894f15cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('transformers_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
